**SUIM: Semantic Segmentation of Underwater Imagery** is a dataset for a semantic segmentation task. It is used in the environmental research, and in the robotics industry. 

The dataset consists of 1550 images with 5000 labeled objects belonging to 8 different classes including *waterbody_background*, *fish_and_vertebrates*, *reefs_and_invertebrates*, and other: *sea-floor_and_rocks*, *human_divers*, *wrecks_and_ruins*, *aquatic_plants_and sea-grass*, and *robots*.

Images in the SUIM dataset have pixel-level semantic segmentation annotations. All images are labeled (i.e. with annotations). There are 2 splits in the dataset: *train_val* (1440 images) and *test* (110 images). The dataset was released in 2020 by the <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">University of Minnesota</span>.

Here are the visualized examples for the classes:

[Dataset classes](https://github.com/dataset-ninja/suim/raw/main/visualizations/classes_preview.webm)
